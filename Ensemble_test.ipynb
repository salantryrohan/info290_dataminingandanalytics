{
 "metadata": {
  "name": "Ensemble_test"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import json\n",
      "from itertools import islice\n",
      "from collections import Counter, defaultdict\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import re\n",
      "import nltk\n",
      "\n",
      "# sklean\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "#\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from itertools import izip\n",
      "import numpy\n",
      "from collections import Counter,defaultdict\n",
      "import math\n",
      "from collections import OrderedDict\n",
      "\n",
      "# our bayes\n",
      "from bayes import NaiveBayes\n",
      "\n",
      "# news group data\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "\n",
      "print os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/ajrenold/Dropbox/iSchool/2013Spring/DataMining/yelp_project\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_dict = {}\n",
      "file_dict['reviews'] = 'yelp_academic_dataset_review.json'\n",
      "file_dict['stopwords'] = 'stop-words-english3-google.txt'\n",
      "file_dict['business'] = 'yelp_academic_dataset_business.json'\n",
      "file_dict['users'] = 'yelp_academic_dataset_user.json'\n",
      "\n",
      "review_file = open(file_dict['reviews'])\n",
      "review_file_s = islice(review_file,None)\n",
      "print file_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'reviews': 'yelp_academic_dataset_review.json', 'stopwords': 'stop-words-english3-google.txt', 'users': 'yelp_academic_dataset_user.json', 'business': 'yelp_academic_dataset_business.json'}\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# list from http://stackoverflow.com/questions/1803628/raw-list-of-person-names\n",
      "f = open('stop_names.csv')\n",
      "\n",
      "stop_names = {}\n",
      "\n",
      "for line in islice(f,None):\n",
      "    word = line.lower().strip()[line.find(',')+1:]\n",
      "    if word not in stop_names:\n",
      "        stop_names[word] = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_json = open(file_dict['reviews'])\n",
      "reviews_for_df = [ json.loads(line) for line in review_json ]\n",
      "review_df = pd.DataFrame(reviews_for_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_json = open(file_dict['users'])\n",
      "user_for_df = [ json.loads(line) for line in user_json ]\n",
      "user_df = pd.DataFrame(user_for_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create avg_useful_votes in users_df\n",
      "user_df = user_df.set_index(['user_id'])\n",
      "user_df['useful_votes'] = user_df['votes'].apply(lambda x: x['useful'])\n",
      "user_df['avg_useful_votes'] = user_df.apply(lambda series: float(series['useful_votes'])/float(series['review_count']),axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "business_json = open(file_dict['business'])\n",
      "business_json_list = [ json.loads(line) for line in islice(business_json,None) ]\n",
      "\n",
      "business_dict = {}\n",
      "for biz in business_json_list:\n",
      "    business_dict[biz['business_id']] = biz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 229907 entries, 0 to 229906\n",
        "Data columns:\n",
        "business_id    229907  non-null values\n",
        "date           229907  non-null values\n",
        "review_id      229907  non-null values\n",
        "stars          229907  non-null values\n",
        "text           229907  non-null values\n",
        "type           229907  non-null values\n",
        "user_id        229907  non-null values\n",
        "votes          229907  non-null values\n",
        "dtypes: int64(1), object(7)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenize_avg_useful_votes(votes):\n",
      "    if votes == 0:\n",
      "        return \"userAvg0 \"*3\n",
      "    elif votes <= 0.5:\n",
      "        return \"userAvgPoint5\"\n",
      "    elif votes <= 1:\n",
      "        return \"userAvg1\"\n",
      "    elif votes <= 1.5:\n",
      "        return \"userAvg1Point5\"\n",
      "    elif votes <= 2:\n",
      "        return \"userAvg2\"\n",
      "    elif votes <= 2.5:\n",
      "        return \"userAvg2Point5 \"*2\n",
      "    else:\n",
      "        return \"userAvgHigh \"*4\n",
      "    \n",
      "def append_user_token(series):\n",
      "    try:\n",
      "        return series['text'] + ' ' + user_df.ix[series['user_id']]['useful_token']\n",
      "    except:\n",
      "        return series['text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_df['useful_token'] = user_df['avg_useful_votes'].apply(tokenize_avg_useful_votes)\n",
      "review_df['text'] = review_df.apply(append_user_token, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def useful_votes(votes):\n",
      "    if votes['useful'] < 14:\n",
      "        return votes['useful']\n",
      "    else:\n",
      "        return 14"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract useful_votes from votes column\n",
      "\n",
      "#review_df['tokens'] = review_df['text'].apply(nltk.word_tokenize) # tokenize using nltk\n",
      "review_df['useful_votes'] = review_df['votes'].apply(useful_votes) # extract useful votes\n",
      "review_df = review_df.set_index(['review_id']) # index on review_id\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# partition data to train and test\n",
      "\n",
      "train = []\n",
      "test = []\n",
      "for row in islice(review_df[['text','useful_votes','business_id']].iterrows(),None):\n",
      "    if 'Restaurants' in business_dict[row[1]['business_id']]['categories']:\n",
      "        train_or_test = np.random.uniform()\n",
      "        # partition training data\n",
      "        if train_or_test < 0.8:\n",
      "            train.append(row[1])\n",
      "        # partition testing data\n",
      "        else:\n",
      "            test.append(row[1])\n",
      "        \n",
      "train_df = pd.DataFrame(train)\n",
      "test_df = pd.DataFrame(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 126714 entries, fWKvX83p0-ka4JS3dc6E5A to z5b2p5TbCg0uaIiIe8n62w\n",
        "Data columns:\n",
        "text            126714  non-null values\n",
        "useful_votes    126714  non-null values\n",
        "business_id     126714  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The history saving thread hit an unexpected error (OperationalError('database is locked',)).History will not be written to the database.\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 31716 entries, XtnfnYmnJYi71yIuGsXIUA to ENmRNlah1ex6xh6iCz13Ng\n",
        "Data columns:\n",
        "text            31716  non-null values\n",
        "useful_votes    31716  non-null values\n",
        "business_id     31716  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get reviews with useful votes from training data\n",
      "useful_review_df = train_df[train_df['useful_votes']>=1] # 40 percent votes are 0 , 28 % are 1 , discarding those\n",
      "useful_review_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 74119 entries, fWKvX83p0-ka4JS3dc6E5A to z5b2p5TbCg0uaIiIe8n62w\n",
        "Data columns:\n",
        "text            74119  non-null values\n",
        "useful_votes    74119  non-null values\n",
        "business_id     74119  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create labels for NaiveBayes\n",
      "train_labels = []\n",
      "train_text = []\n",
      "for row in train_df.iterrows():\n",
      "    if row[1]['useful_votes'] == 0:\n",
      "        train_labels.append('0')\n",
      "        train_text.append(row[1]['text'])\n",
      "    elif row[1]['useful_votes'] >= 4:\n",
      "        train_labels.append('1')\n",
      "        train_text.append(row[1]['text'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word = 'jumpping'\n",
      "word = re.sub(r'(.)\\1+', r'\\1', word)\n",
      "word"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "'jumping'"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train NaiveBayes\n",
      "% time clfr = NaiveBayes(train_text, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'1': 0.179598193427815, '0': 0.820401806572185}\n",
        "4355"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 23.19 s, sys: 0.54 s, total: 23.73 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 23.78 s\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_probs = clfr.data_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print abs(math.log(data_probs['useravg0']['1'],10))\n",
      "#print abs(math.log(data_probs['useravg0']['0'],10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_features = clfr.max_entropy(1500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_exclude = ['PRP','PRP$','WRB','CC','IN', 'WDT', 'WP', 'WP$', 'WRB', 'UH', 'CD', 'EX', 'MD', 'POS', 'PDT', 'LS', 'TO']\n",
      "feature_words = [ f[1] for f in max_features ]\n",
      "tagged_feature_words = nltk.pos_tag(feature_words)\n",
      "features = [ word[0] for word in tagged_feature_words if word[1] not in pos_exclude and word[0] not in stop_names ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(features)\n",
      "print features[0:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create labels for entropy\n",
      "useful_reviews_labels = []\n",
      "for votes in useful_review_df['useful_votes'][:]:\n",
      "    if votes < 3:\n",
      "        useful_reviews_labels.append(0)\n",
      "    elif votes >= 3:\n",
      "        useful_reviews_labels.append(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "corpus = useful_review_df['text'][:10000]\n",
      "corpuslabels = np.array(useful_reviews_labels[:10000])\n",
      "\n",
      "vectorizer1 = TfidfVectorizer()\n",
      "X1 = vectorizer1.fit_transform(corpus) # sparse matrix with tfidf weights\n",
      "features = vectorizer1.get_feature_names()\n",
      "X1 = X1.toarray() # convert into 2d numpy array\n",
      "\n",
      "countD = len(corpuslabels)\n",
      "\n",
      "def calinfoD():\t\n",
      "\ttotcnt = countD\t\n",
      "\tclasscnt = Counter(corpuslabels)\n",
      "\tinfod = 0.0\n",
      "\n",
      "\tfor classname,count in classcnt.iteritems():\n",
      "\t\t#print classname,'and',count\n",
      "\t\tpi = float(count)/totcnt\t\t\n",
      "\t\tlogpi = float(math.log(pi,2))\t\t\n",
      "\t\t#print pi*logpi\n",
      "\t\tinfod = infod + (pi*logpi)\n",
      "\n",
      "\tinfod = -1*infod\n",
      "\n",
      "\treturn infod\n",
      "\n",
      "\n",
      "def calinfoDj(featurename):\n",
      "\t# two clases word present and word absent\n",
      "\tindex = features.index(featurename)\n",
      "\ttotal = len(features)\n",
      "\n",
      "\n",
      "\tDjpresent = corpuslabels[X1[:,index] > 0] # column slicing using numpy\n",
      "\tDjabsent = corpuslabels[X1[:,index] == 0] # column slicing using numpy\n",
      "\n",
      "\t\t\n",
      "\ttotcnt = len(Djpresent)\n",
      "\tclasscnt = Counter(Djpresent)\n",
      "\n",
      "\ttotcnt1 = len(Djabsent)\n",
      "\tclasscnt1 = Counter(Djabsent)\n",
      "\t\n",
      "\tinfodpresent = 0.0\n",
      "\n",
      "\tfor classname,count in classcnt.iteritems():\t\t\n",
      "\t\tpi = float(count)/totcnt\t\t\n",
      "\t\tlogpi = float(math.log(pi,2))\t\t\t\t\n",
      "\t\tinfodpresent = infodpresent + (pi*logpi)\n",
      "\n",
      "\tinfodpresent = -1*infodpresent\n",
      "\n",
      "\tinfodabsent = 0.0\n",
      "\n",
      "\tfor classname,count in classcnt1.iteritems():\t\t\n",
      "\t\tpi = float(count)/totcnt\t\t\n",
      "\t\tlogpi = float(math.log(pi,2))\t\t\t\t\n",
      "\t\tinfodabsent = infodabsent + (pi*logpi)\n",
      "\n",
      "\tinfodabsent = -1*infodabsent\n",
      "\n",
      "\tresult = ((float(totcnt)/total)*infodpresent) + ((float(totcnt1)/total)*infodabsent)\n",
      "\treturn result\t\n",
      "\t\n",
      "def calinfogain():\n",
      "\n",
      "\tfeat_entr = list() # list of tuples\n",
      "\tinfod = calinfoD()\n",
      "\n",
      "\tfor feat in features:\n",
      "\t\tentr_feat = calinfoDj(feat)\n",
      "\t\tinfogain = infod - entr_feat\n",
      "\n",
      "\t\tfeat_entr.append((infogain,feat))\n",
      "\n",
      "\tfeat_entr_sorted = sorted(feat_entr, reverse=True)\n",
      "\treturn feat_entr_sorted\n",
      "    \n",
      "%time entropy_features = calinfogain()\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"entropy_words = [ item[1] for item in entropy_features]\n",
      "entropy_words = set(entropy_words[-1500:-200])\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"intersect = entropy_words.intersection(set(feature_words))\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"print len(intersect)\n",
      "print list(intersect)\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Re-write to optimize time\n",
      "#### NOT YET FINISHED\n",
      "\n",
      "def get_review_len_token(review_len):\n",
      "    if review_len <= 100:\n",
      "        return 'review_len_100'\n",
      "    elif review_len <= 200:\n",
      "        return 'review_len_200'\n",
      "    elif review_len <= 300:\n",
      "        return 'review_len_300'\n",
      "    elif review_len <= 400:\n",
      "        return 'review_len_400'\n",
      "    elif review_len <= 500:\n",
      "        return 'review_len_500'\n",
      "    elif review_len <= 600:\n",
      "        return 'review_len_600'\n",
      "    elif review_len <= 700:\n",
      "        return 'review_len_700'\n",
      "    elif review_len <= 800:\n",
      "        return 'review_len_800'\n",
      "    elif review_len <= 900:\n",
      "        return 'review_len_900'\n",
      "    elif review_len <= 1000:\n",
      "        return 'review_len_1000'\n",
      "    else:\n",
      "        return 'review_len_long'\n",
      "\n",
      "def tokenize(text):\n",
      "    text = re.sub(r\"[\\n\\.,;\\!\\?\\(\\)\\[\\]\\*/:+\\-\\~]\",\" \",text.lower())\n",
      "    text = re.sub(r\"(\\b[\\d]+\\b|\\b[\\d]+[a-z]+\\b)\",\" \",text)\n",
      "    #inplist = nltk.word_tokenize(text)    \n",
      "    inplist = text.split(' ')\n",
      "    finallist = list()\n",
      "    result = list()\n",
      "    # wordcorrect for tokens\n",
      "    #finallist = wordcorrect(inplist)\n",
      "    finallist = inplist\n",
      "    \n",
      "    finallist.append(get_review_len_token(len(inplist)))\n",
      "    \n",
      "    for i in range(len(finallist)):        \n",
      "        #if stops.has_key(inplist[i]): # remove stop words\n",
      "        #   continue\n",
      "        if '$' in inplist[i]:\n",
      "            result.append('priceMention')\n",
      "        else:\n",
      "            result.append(inplist[i])\n",
      "    \n",
      "    return result\n",
      "\n",
      "def create_training_input(text,feature_words):\n",
      "    #extracted_features = tfidf_vectorize(text)\n",
      "    count_vect = CountVectorizer(tokenizer = tokenize,vocabulary = feature_words, min_df=30)\n",
      "    return count_vect, count_vect.fit_transform(text)\n",
      "\n",
      "%time count_vect, training_input = create_training_input(useful_review_df['text'][:],features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 22.26 s, sys: 0.20 s, total: 22.46 s\n",
        "Wall time: 22.47 s\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train LRModel\n",
      "trnglabels = useful_review_df['useful_votes'][:]\n",
      "LRModel = LinearRegression()\n",
      "%time LRModel.fit(training_input,trnglabels)\n",
      "modelpar = LRModel.coef_\n",
      "print min(modelpar),max(modelpar)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.69 s, sys: 0.02 s, total: 1.71 s\n",
        "Wall time: 1.71 s\n",
        "-1.02130605967 1.58731371386\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test LRModel on its own\n",
      "testrange = count_vect.fit_transform(test_df['text'][:])\n",
      "pred_results = LRModel.predict(testrange.toarray())\n",
      "res = zip(test_df['useful_votes'][:].values,pred_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LRModel RMSE\n",
      "errors = []\n",
      "for r in res:\n",
      "    err = abs(r[0]-r[1])\n",
      "    errors.append(err)\n",
      "    \n",
      "print np.sqrt(np.mean([ e**2 for e in errors ]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.75152282144\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = defaultdict(Counter)\n",
      "results = []\n",
      "\n",
      "for i,item in islice(enumerate(test_df['text']),None):\n",
      "    label = clfr.label_new(item)\n",
      "    #print label,test_df['useful_votes'][i]\n",
      "    if label[0][1] == '1':\n",
      "        testrange = count_vect.fit_transform([item])\n",
      "        votes = LRModel.predict(testrange.toarray())\n",
      "        #print votes[0]\n",
      "        results.append((votes[0],test_df['useful_votes'][i]))\n",
      "        #results.append((1.5,test_df['useful_votes'][i]))\n",
      "    #elif label[0][1] == '2':\n",
      "    #    results.append((4.5,test_df['useful_votes'][i]))\n",
      "    #elif label[0][1] == '3' or label[0][1] == '2':\n",
      "    #    testrange = count_vect.fit_transform([item])\n",
      "    #    votes = LRModel.predict(testrange.toarray())\n",
      "    #    results.append((votes[0],test_df['useful_votes'][i]))\n",
      "    else:\n",
      "        results.append((0,test_df['useful_votes'][i]))\n",
      "        #print 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_df['text'][11], results[11]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Labeling RMSE\n",
      "# >= 4 is 2.72\n",
      "#\n",
      "# >= 2 is 2.69\n",
      "# Best = \n",
      "# 1.716\n",
      "\n",
      "errors = []\n",
      "for r in results:\n",
      "    err = r[0]-r[1]\n",
      "    errors.append(err)\n",
      "\n",
      "print np.sqrt(np.mean([ e**2 for e in errors ]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.71574306806\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = defaultdict(Counter)\n",
      "for i,item in enumerate(test_df['text']):\n",
      "    label = clfr.label_new(item)\n",
      "    #print(label,correct_labels[i])\n",
      "    if test_df['useful_votes'][i] > 0:\n",
      "        correct = '1'\n",
      "    else:\n",
      "        correct = '0'\n",
      "    if label[0][1] == correct:\n",
      "        matches['labeled'][correct] += 1\n",
      "    else:\n",
      "        matches['not-labeled'][correct] += 1\n",
      "    matches['total'][correct] += 1\n",
      "    \n",
      "print 'class 1 percent correct', (float(matches['labeled']['1']) / matches['total']['1'] )\n",
      "print 'class 0 percent correct', (float(matches['labeled']['0']) / matches['total']['0'] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "class 1 percent correct 0.666917697687\n",
        "class 0 percent correct 0.649083799739\n"
       ]
      }
     ],
     "prompt_number": 32
    }
   ],
   "metadata": {}
  }
 ]
}